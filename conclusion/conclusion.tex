\chapter{Conclusion}

\section{Ethical Considerations}

The main point is that technology isn't evil, those who use it may be.

The intended use of this technology is to accelerate humanity's use of robots. We believe that if multiple robots from different owners, with different goals, can safely collaborate, then many new things can be done. Like good drone delivery, space exploration, multi-tenanted space mining, and better and safer self-driving cars.

The least ethical way to use this would be to use it to secure the communications of weapons, for example, nuclear missiles. This isn't something that we can prevent, but it's unlikely to be implemented since militaries usually operate in a centralised manner, and so won't need to think about securing themselves against attacks in decentralised systems.

Another unethical way to use this would be to secure mass surveillance robots, for example, police drones which could patrol the streets for people. Here an attacker would aim to hide by influencing the drones away from certain areas, now obviously, this isn't something we want to happen, but we cannot prevent it, especially since these defences are likely to be needed in case someone takes control of one of these police robots.

However there are also cases where this is ethical, for example, if a country's infrastructure is based on decentralised communication, it is super-duper resistant to authorities shutting it down (Kashmir/Iran), or other armies from disrupting it (Russia-Ukraine). It also prevents hacker groups from being able to hold entire countries to ransom like what happened with WannaCry.

